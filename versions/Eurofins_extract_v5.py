import pandas as pd
import unicodedata
import re
from collections import defaultdict


# === Script : EXTRACT VALUE WITH KEYWORD IN AN EXCEL FORMAT - TABLEURS EUROFINS ===
# = v1 : Test import from Excel raw DF-Excel and keyword-based extract
# = v1.5 : Multiple keywords test
# = v2 : Normalizing text and splitting data into keywords based on value or sum
# = v3 : Extraction validated for general keyword with random pick
# = v4 : Adapting the script to allow HAP to be separated from Naphtalene/HAP
#
file_path = "00_INPUT/R√©sultats Eurofins 06052025.xlsm"
sheet_name = "Comparer les √©chantillons"

df_raw = pd.read_excel(file_path, sheet_name=sheet_name, header=None)
print("‚úÖ Fichier charg√©.")

# Based on Excel format from Eurofins, without blank parts
# Starting with CodeEuro/CodeArt/Date + Data from L5-C4 index 4,3
headers = ['Code Eurofins', 'Code Artelia', 'Date pr√©l√®vement'] + df_raw.iloc[4, 3:].tolist()

header_data_only = [str(col).strip() for col in df_raw.iloc[4, 3:].tolist()]
header_index_map = {i: header_data_only[i] for i in range(len(header_data_only))}

# Data values from line 6, index 5
df = df_raw.iloc[5:].copy()
df.columns = headers
df = df.reset_index(drop=True)

df = df.dropna(axis=1, how='all')
df.columns = pd.Index([str(c).strip() for c in df.columns])

header_index_to_df_col_index = {}

for i, col in enumerate(header_data_only):
    if i + 3 >= len(df.columns):
        continue

    df_col_name = df.columns[i + 3]
    for i in range(len(header_data_only)):
        if i + 3 < len(df.columns):
            header_index_to_df_col_index[i] = i + 3






# ==== CLEANING FUNCTIONS ====
#
# Normalizing text in the headers but will also be applied to text user input
def normalize(text):
    if pd.isna(text):
        return ""
    text = str(text).lower()
    text = unicodedata.normalize('NFD', text).encode('ascii', 'ignore').decode('utf-8')
    # Adding spaces before and after to be able to use it to separate word like ethylbenzene
    return " " + text.strip() + " "

def clean_tokens(text):
    if pd.isna(text):
        return []
    text = str(text).lower()
    text = unicodedata.normalize('NFD', text).encode('ascii', 'ignore').decode('utf-8')  # remove accents
    return re.findall(r'[a-z0-9]+', text)  # keep only alphanum words

# ==================== DEBUG FUNCTION =============================
# Used to convert index to Excel columns
def col_idx_to_excel_letter(idx):
    letter = ''
    while idx >= 0:
        letter = chr(idx % 26 + 65) + letter
        idx = idx // 26 - 1
    return letter
# ==================== DEBUG FUNCTION =============================




# ==== PROCESSING FUNCTIONS ====
#
# Looking for the general keywords to match headers with it - returning index of columns
def get_matching_columns(headers, keywords):
    matched = {kw: [] for kw in keywords}
    summed = {kw: [] for kw in keywords}

    # Adding keywords for global data
    sum_keywords = {"somme", "total", "addition", "synthese", "synth√®se"}

    for i, col in enumerate(headers):
        # No % data
        if "%" in str(col):
            continue

        tokens_col = clean_tokens(col)

        for kw in keywords:
            tokens_kw = clean_tokens(kw)
            # print(f"üîç TEST kw='{kw}' | col='{col}' | tokens_kw={tokens_kw} | tokens_col={tokens_col}")
            if all(tok in tokens_col for tok in tokens_kw):
                # print(f"‚úÖ VRAI MATCH : kw='{kw}' match avec col='{col}'")
                matched[kw].append(i)
                col_norm = col.lower().replace(" ", "")
                if any(word in tokens_col for word in sum_keywords) or "c5-c10" in col_norm or "c10-c40" in col_norm:
                    summed[kw].append(i)

    return matched, summed

def afficher_colonnes_detectees(columns_dict, df, titre="Colonnes d√©tect√©es"):
    print(f"\nüìä {titre} :")
    for kw, index_list in columns_dict.items():
        if index_list:
            display = []
            for idx in index_list:
                try:
                    df_col_index = idx + 3  # D√©calage logique vers df.columns
                    if df_col_index >= len(df.columns):
                        continue
                    col_name = df.columns[df_col_index]
                    col_letter = col_idx_to_excel_letter(df_col_index)
                    display.append(f"{col_letter} ({col_name})")
                except Exception as e:
                    print(f"‚ö†Ô∏è Erreur pour index '{idx}': {e}")
                    continue
            print(f"‚úÖ {kw} ‚Üí {display}")


def extraire_valeurs_generales(df, matched_columns, general_keywords):
    resultats = {}
    for kw in general_keywords:
        if kw.lower() == "hap":
            continue
        if matched_columns.get(kw):
            for idx in matched_columns[kw]:
                df_col_index = idx + 3
                if df_col_index >= len(df.columns):
                    continue
                col_name = df.columns[df_col_index]
                for i in range(len(df)):
                    try:
                        val = df.at[i, col_name]
                        if isinstance(val, pd.Series):
                            val = val[val.notna()]
                            val = val[val.astype(str).str.strip() != ""]
                            if val.empty:
                                continue
                            val = val.iloc[0]
                        elif pd.isna(val) or str(val).strip() == "":
                            continue
                    except Exception:
                        continue

                    val_str = str(val).strip()
                    if val_str.startswith("<"):
                        val_str = f"<LQ ({val_str})"

                    artelia = df.at[i, 'Code Artelia']
                    if pd.isna(artelia):
                        continue

                    if artelia not in resultats:
                        resultats[artelia] = {}

                    resultats[artelia][kw] = val_str
    return resultats

def extraire_valeurs_hap(df, matched_columns):
    resultats = {}
    def normalize(text):
        text = str(text).lower()
        return unicodedata.normalize('NFD', text).encode('ascii', 'ignore').decode('utf-8')

    for idx in matched_columns.get("hap", []):
        df_col_index = idx + 3
        if df_col_index >= len(df.columns):
            continue
        col_name = df.columns[df_col_index]
        col_name_norm = normalize(col_name)
        true_kw = "hap + naphtal√®ne" if "naphtalene" in col_name_norm else "hap"
        # print(f"\nüîç Colonne d√©tect√©e : '{col_name}' ‚Üí Class√©e comme '{true_kw}'")
        for i in range(len(df)):
            try:
                val = df.at[i, col_name]
                if isinstance(val, pd.Series):
                    val = val[val.notna()]
                    val = val[val.astype(str).str.strip() != ""]
                    if val.empty:
                        continue
                    val = val.iloc[0]
                elif pd.isna(val) or str(val).strip() == "":
                    continue
            except Exception:
                continue

            val_str = str(val).strip()
            if val_str.startswith("<"):
                val_str = f"<LQ ({val_str})"

            artelia = df.at[i, 'Code Artelia']
            if pd.isna(artelia):
                continue

            if artelia not in resultats:
                resultats[artelia] = {}

            resultats[artelia][true_kw] = val_str
            # print(f"‚úÖ Ajout : Artelia = {artelia} | {true_kw} = {val_str}")
    return resultats

def afficher_groupement_par_artelia(df, resultats_artelia):
    print("\nüì• R√©sum√© regroup√© par code Artelia :")
    tous_codes_artelia = df['Code Artelia'].dropna().unique()

    for artelia in tous_codes_artelia:
        mesures = resultats_artelia.get(artelia, {})
        if not mesures:
            print(f"Artelia: {artelia} | Pas d'analyse d√©tect√©e")
        else:
            ligne = f"Artelia: {artelia}"
            for comp, val in mesures.items():
                ligne += f" | {comp} = {val}"
            print(ligne)

    print("\nüîé DEBUG ‚Äî Valeurs HAP par √©chantillon :")
    for artelia in tous_codes_artelia:
        hap_val = resultats_artelia.get(artelia, {}).get("hap", "‚Äî")
        hap_naphtalene_val = resultats_artelia.get(artelia, {}).get("hap + naphtal√®ne", "‚Äî")
        print(f"[HAP] - Artelia: {artelia} | HAP = {hap_val} | HAP + naphtal√®ne = {hap_naphtalene_val}")






# = PROCESSING PART = #
#
general_keywords = [
    "benzene",
    "hap", # Special treatment for logical issue regarding naphta

    # SHORT CARBON
    "c5 - c10", # = TOTAL !
    "c6 - c8", # ALI
    "c8 - c10", # ALI ou TOTAL
    "c5 - c6", # ALI
    "c9 - c10", # ARO
    "c6 - c9", # ARO
    "c5 - c8", # = TOTAL !

    # LONG CARBON
    "c10 - c40", # = TOTAL !

    # 8 PARTS
    "c10 - c12",
    "c12 - c16",
    "c16 - c20",
    "c20 - c24",
    "c24 - c28",
    "c28 - c32",
    "c32 - c36",
    "c36 - c40",
    # 4 PARTS
    "nc10 - nc16",
    "nc16 - nc22",
    "nc22 - nc30",
    "nc30 - nc40",
]


matched_columns, summed_columns = get_matching_columns(df.columns[3:], general_keywords)

afficher_colonnes_detectees(matched_columns, df, titre="Colonnes d√©tect√©es par mot-cl√©")
afficher_colonnes_detectees(summed_columns, df, titre="Colonnes qui semblent d√©j√† contenir une somme")

resultats_generaux = extraire_valeurs_generales(df, matched_columns, general_keywords)
resultats_hap = extraire_valeurs_hap(df, matched_columns)

resultats_artelia = defaultdict(dict)
for dico in [resultats_generaux, resultats_hap]:
    for k, v in dico.items():
        resultats_artelia[k].update(v)

afficher_groupement_par_artelia(df, resultats_artelia)



# = EXPORTING PART
#
# df_export = pd.DataFrame.from_dict(resultats_artelia, orient='index')
#
# # R√©initialisation de l‚Äôindex (Code Artelia devient une colonne)
# df_export.reset_index(inplace=True)
# df_export.rename(columns={"index": "Code Artelia"}, inplace=True)
#
# # On s‚Äôassure que tous les codes Artelia sont inclus, m√™me sans valeurs
# df_export_complet = pd.DataFrame({'Code Artelia': tous_codes_artelia})
# df_export = pd.merge(df_export_complet, df_export, on='Code Artelia', how='left')
#
# # ‚úÖ Export dans un fichier Excel
# output_file = "r√©sum√©_extraction_artelia.xlsx"
# df_export.to_excel(output_file, index=False)
# print(f"\n‚úÖ R√©sum√© export√© dans le fichier : {output_file}")